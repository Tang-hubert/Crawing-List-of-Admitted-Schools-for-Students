{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a60986cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (23.2.1)\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2588d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (from pytesseract) (23.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (from pytesseract) (10.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (10.0.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (4.8.0.76)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Requirement already satisfied: pathlib in c:\\users\\user\\desktop\\backup\\brt\\projects\\crawing-list-of-admitted-schools-for-students\\venv\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "# !pip install tensorflow\n",
    "!pip install Pillow\n",
    "!pip install lxml\n",
    "!pip install opencv-python\n",
    "!pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f617ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import base64\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "from pytesseract import pytesseract\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cfb6b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd C:\\Users\\user\\Desktop\\Working\\向高手求救--落點分析交叉查榜依考區查榜\n",
    "\n",
    "# *交叉查榜*.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "999c2939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\backup\\brt\\Projects\\Crawing-List-of-Admitted-Schools-for-Students\\data\n",
      "正1\n",
      "\n",
      "111*x**0\n",
      "\n",
      "正3\n",
      "\n",
      "112\"xx*2\n",
      "\n",
      "正……\n",
      "\n",
      "110xx%*2\n",
      "\n",
      "正7\n",
      "\n",
      "110x«x*8\n",
      "\n",
      "正9\n",
      "\n",
      "110xxx*9\n",
      "\n",
      "正11\n",
      "\n",
      "110xxx*9\n",
      "\n",
      "正13\n",
      "\n",
      "110x«x*5\n",
      "\n",
      "正1……\n",
      "\n",
      "112xxx*4\n",
      "\n",
      "正17\n",
      "\n",
      "110xx%*7\n",
      "\n",
      "備1\n",
      "\n",
      "110*xx*0\n",
      "\n",
      "備3\n",
      "\n",
      "L11xxx*5\n",
      "\n",
      "備5\n",
      "\n",
      "111xxx*8\n",
      "\n",
      "備7\n",
      "\n",
      "110xxx*3\n",
      "\n",
      "備9\n",
      "\n",
      "110xx%*4\n",
      "\n",
      "備11\n",
      "\n",
      "110xx%*4\n",
      "\n",
      "備13\n",
      "\n",
      "111xxx*8\n",
      "\n",
      "備15\n",
      "\n",
      "L11xxx*5\n",
      "\n",
      "備 17\n",
      "\n",
      "L11xxx*7\n",
      "\n",
      "備 19\n",
      "\n",
      "111*x**6\n",
      "\n",
      "備21\n",
      "\n",
      "110xx%*2\n",
      "\n",
      "備23\n",
      "\n",
      "112*xx*3\n",
      "\n",
      "備25\n",
      "\n",
      "L11xxx*2\n",
      "\n",
      "110x«x*8\n",
      "\n",
      "110xx%*4\n",
      "\n",
      "110*xx*0\n",
      "\n",
      "110xx%*7\n",
      "\n",
      "L1lxxx«1\n",
      "\n",
      "L1lxxx«1\n",
      "\n",
      "112*x**0\n",
      "\n",
      "正2\n",
      "\n",
      "L11xxx*3\n",
      "\n",
      "正乙ˍ\n",
      "\n",
      "112*xx*8\n",
      "\n",
      "正6\n",
      "\n",
      "110xx%*4\n",
      "\n",
      "正8\n",
      "\n",
      "L1lxxx«1\n",
      "\n",
      "正1〔)\n",
      "\n",
      "110xxx*9\n",
      "\n",
      "正12\n",
      "\n",
      "110xxx*9\n",
      "\n",
      "正1乙ˍ\n",
      "\n",
      "110x«x*5\n",
      "\n",
      "正16\n",
      "\n",
      "110xxx*3\n",
      "\n",
      "正18\n",
      "\n",
      "113%x%*7\n",
      "\n",
      "備2\n",
      "\n",
      "L11xxx*3\n",
      "\n",
      "備4\n",
      "\n",
      "110xxx*9\n",
      "\n",
      "備6\n",
      "\n",
      "L11xxx*7\n",
      "\n",
      "備8\n",
      "\n",
      "110xx%*4\n",
      "\n",
      "備10\n",
      "\n",
      "111xxx*8\n",
      "\n",
      "備 12\n",
      "\n",
      "111*xx*9\n",
      "\n",
      "備 M\n",
      "\n",
      "110xx%*7\n",
      "\n",
      "備16\n",
      "\n",
      "110*x**6\n",
      "\n",
      "備18\n",
      "\n",
      "110xxx*3\n",
      "\n",
      "備20\n",
      "\n",
      "111*xx*9\n",
      "\n",
      "備22\n",
      "\n",
      "L11xxx*3\n",
      "\n",
      "備24\n",
      "\n",
      "L1lxxx«1\n",
      "\n",
      "110x«x*8\n",
      "\n",
      "110xxx*3\n",
      "\n",
      "110xxx*3\n",
      "\n",
      "110xx%*2\n",
      "\n",
      "111xxx*8\n",
      "\n",
      "L11xxx*3\n",
      "\n",
      "112*xx*3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\User\\Desktop\\backup\\brt\\Projects\\Crawing-List-of-Admitted-Schools-for-Students\\data\n",
    "\n",
    "for file in glob.iglob('*交叉查榜*.html'):\n",
    "    # print(file)\n",
    "    processing_department(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "68113375",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def processing_department(filename):\n",
    "    \n",
    "    with open(filename, 'r', encoding=\"utf-8\") as file:\n",
    "        html = file.read()\n",
    "        # print(html)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    fields = ['rank', 'exam_location', 'stuno', 'univ',  'year']\n",
    "    df = pd.DataFrame(columns=fields)\n",
    "    df1 = pd.DataFrame(columns=fields)\n",
    "    df2 = pd.DataFrame(columns=fields)\n",
    "\n",
    "    str = soup.head.find_all('title')[0].text\n",
    "    pos = str.find('年')\n",
    "    year = str[pos-3:pos]  # str[5:8] str[5], str[6], str[7]\n",
    "\n",
    "    str = soup.head.find_all('title')[0].text\n",
    "    pos = str.find('-')\n",
    "    univ = str[:pos].rstrip()\n",
    "\n",
    "    dark_list = soup.body.find_all(bgcolor=\"#DEDEDC\") # 褐色\n",
    "    df1 = processing_list(univ, year, dark_list, df)\n",
    "    # print(df1)\n",
    "    \n",
    "    white_list = soup.body.find_all(bgcolor=\"#FFFFFF\") # 白色\n",
    "    df2 = processing_list(univ, year, white_list, df)\n",
    "    # print(df2)\n",
    "    \n",
    "    # craw more data\n",
    "    \n",
    "    # make two df cross-interleave\n",
    "    max_len = max(len(df1), len(df2))\n",
    "    for i in range(max_len):\n",
    "        if i < len(df1):\n",
    "            df = pd.concat([df, df1.iloc[[i]]], ignore_index=True)\n",
    "        if i < len(df2):\n",
    "            df = pd.concat([df, df2.iloc[[i]]], ignore_index=True)\n",
    "\n",
    "    result_dir = Path(r\"C:\\Users\\User\\Desktop\\backup\\brt\\Projects\\Crawing-List-of-Admitted-Schools-for-Students\\result\",f'{univ}.csv')\n",
    "    df.to_csv(path_or_buf = result_dir, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c95da709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_list(univ, year, list, df):\n",
    "    # print(list) # html\n",
    "    #print(df)\n",
    "    for dark_item in list:\n",
    "        x = dark_item.children # get message under the soup.body.find_all(bgcolor=\"\")\n",
    "        count = 0\n",
    "        for i in x:\n",
    "            # print(\"i:\",i)\n",
    "            if count == 3:\n",
    "                # print(\"i:\")\n",
    "                # print(i.text)  #正1\n",
    "                # rank = i.text\n",
    "                try:\n",
    "                    base64_str = i.find_all('img')[0]['src'].split(',')[1]\n",
    "                except IndexError:\n",
    "                    # print(\"not exist\")\n",
    "                    rank = \"None\"\n",
    "                else:\n",
    "                    with open(\"rank.png\", \"wb\") as fh:\n",
    "                        fh.write(base64.decodebytes(bytes(base64_str, 'utf-8')))\n",
    "                    path_to_tesseract = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "                    path_to_image = r'rank.png'\n",
    "                    pytesseract.tesseract_cmd = path_to_tesseract\n",
    "                    thresholding_(r'rank.png')\n",
    "                    path_to_image = r'rank.png'\n",
    "                    rank = pytesseract.image_to_string(Image.open(path_to_image), lang='chi_tra', config='--oem 0 --psm 7')\n",
    "                    print(rank)\n",
    "            elif count == 5:\n",
    "                #print(i.find_all('img')[0]['src'].split(',')[1])\n",
    "                base64_str = i.find_all('img')[0]['src'].split(',')[1]\n",
    "                with open(\"num.png\", \"wb\") as fh:\n",
    "                    fh.write(base64.decodebytes(bytes(base64_str, 'utf-8')))\n",
    "                path_to_tesseract = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "                pytesseract.tesseract_cmd = path_to_tesseract\n",
    "                thresholding_(r'num.png')\n",
    "                path_to_image = r'num.png'\n",
    "                stuno = pytesseract.image_to_string(Image.open(path_to_image), lang='eng', config='--oem 1 --psm 7')\n",
    "                print(stuno) # 應試號碼(num)\n",
    "            count += 1\n",
    "    \n",
    "        x = dark_item.find_all('a')\n",
    "        # print(x[0].text[6:]) # 大學\n",
    "        exam_location = x[0].text[6:] \n",
    "        #ptr_df = ptr_df + 1\n",
    "    \n",
    "        dict = {'rank': rank, 'exam_location': exam_location, 'stuno': stuno, 'univ': univ, 'year': year}\n",
    "        df = pd.concat([df, pd.DataFrame([dict])], ignore_index = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "34fd1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding_(png):\n",
    "    if png[0:3] == \"num\":\n",
    "        image = cv2.imread(png)\n",
    "        gray = get_grayscale(image)\n",
    "        thresh_ = thresholding(gray)\n",
    "        cv2.imwrite('num.png', thresh_)\n",
    "    else:\n",
    "        image = cv2.imread(png)\n",
    "        gray = get_grayscale(image)\n",
    "        thresh_ = thresholding(gray)\n",
    "        cv2.imwrite('rank.png', thresh_)        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f4541",
   "metadata": {},
   "source": [
    "# cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a389f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread(r'C:\\Users\\User\\Desktop\\backup\\brt\\Projects\\Crawing-List-of-Admitted-Schools-for-Students\\data\\rank.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9fe78ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to grayscale\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Remove noise from the image\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image, 5)\n",
    " \n",
    "# Thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "    \n",
    "# Erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "# Opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "# Skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "# Template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6053425",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = get_grayscale(img)\n",
    "thresh = thresholding(gray)\n",
    "opening = opening(gray)\n",
    "canny = canny(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "93067ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('My Image.png', thresh)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
